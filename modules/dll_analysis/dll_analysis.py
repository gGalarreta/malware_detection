from sklearn.feature_extraction.text import TfidfVectorizer
from features_handler.k_means import k_means
from features_handler.agglomerative import agglomerative_cluster
import pefile
import os
import numpy as np

class Dll():

  def __init__(self):
    self.test = ""

  def disassemble(self, pe_data, file_name):
    file = open(file_name,"w")
    self.disassemble_imported_symbols(pe_data, file)
    self.disassemble_exported_symbols(pe_data, file)
    file.close()

  def disassemble_imported_symbols(self, pe_data, file):
    try:
      if pe_data.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_IMPORT']].VirtualAddress != 0:
        pe_data.parse_data_directories(directories=[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_IMPORT']])
        for entry in pe_data.DIRECTORY_ENTRY_IMPORT:
          for imp in entry.imports:
            if isinstance(imp.name, str):
              file.write(imp.name)
              file.write("\n")
    except Exception as e:
      print "This sample has some ofuscated values"

  def disassemble_exported_symbols(self, pe_data, file):
    try:
      if pe_data.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']].VirtualAddress != 0:
        pe_data.parse_data_directories(directories=[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']])
        for exp in pe_data.DIRECTORY_ENTRY_EXPORT.symbols:
          if isinstance(exp.name, str):
            file.write(exp.name)
            file.write("\n")
    except Exception as e:
      print "This sample has some ofuscated values"


  def get_dendograms(self, input_directory, rule, folder, index):
    agglomerative_classifier = self.agglomerative_settings(rule)
    data_list = self.get_dlls_from_data(input_directory)
    vectorizer = TfidfVectorizer(min_df=0.05)
    X = vectorizer.fit_transform(data_list)
    idf = vectorizer.idf_
    data = np.reshape(idf, (len(idf), 1))
    agglomerative_classifier.set_cut_off(len(idf))
    output_file = os.getcwd() + "/features_handler/agglomerative/dendograms/" + folder + "_dll.png"
    agglomerative_classifier.get_dendograms(data, output_file)


  def agglomerative_settings(self, rule):
    agglomerative_classifier = agglomerative_cluster.Agglomerative()
    return agglomerative_classifier

  def extract_features(self, input_directory, output_filename, rule):
    cluster = self.cluster_settings(rule)
    data_list = self.get_dlls_from_data(input_directory)
    self.get_top_features(cluster, data_list, output_filename)

  def cluster_settings(self, rule):
    cluster_classifier = k_means.Kmeans()
    vectorizer =  TfidfVectorizer(max_df = float(rule["max_df_tfidvectorize"]), max_features = int(rule["max_features_tfidfvectorize"]), min_df = 0.05, use_idf=True, decode_error='ignore')
    cluster_classifier.set_number_top_words(int(rule["number_of_extracted_top_features"]))
    cluster_classifier.set_number_of_clusters(int(rule["ddl_number_of_clusters"]))
    cluster_classifier.set_vectorizer(vectorizer)
    return cluster_classifier

  def get_top_features(self, cluster, data_list, output_filename):
    cluster.set_data(data_list)
    cluster.extract_top_features(output_filename)

  def get_dlls_from_data(self, input_directory):
    files = os.listdir(input_directory)
    dll_lists = []
    for file in files:
      file_name = input_directory + "/" + file
      file_dlls = self.list_string(self.read_file(file_name))
      dll_lists.append(file_dlls)
    return dll_lists

  def read_file(self, file_name):
    lines = [line.rstrip('\n') for line in open(file_name)]
    lines = np.unique(lines)
    return lines

  def list_string(self, data_list):
    document = ','.join(data_list)
    return document


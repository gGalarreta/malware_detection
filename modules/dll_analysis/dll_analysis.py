from sklearn.feature_extraction.text import TfidfVectorizer
from k_means import k_means
import pefile
import os
import numpy as np

class Dll():

  def __init__(self):
    self.vectorizer = TfidfVectorizer(max_df = 0.75, max_features = 400000, min_df = 0.05, use_idf=True, decode_error='ignore')

  def disassemble(self, pe_data, file_name):
    file = open(file_name,"w")
    self.disassemble_imported_symbols(pe_data, file)
    self.disassemble_exported_symbols(pe_data, file)
    file.close()

  def disassemble_imported_symbols(self, pe_data, file):
    try:
      if pe_data.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_IMPORT']].VirtualAddress != 0:
        pe_data.parse_data_directories(directories=[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_IMPORT']])
        for entry in pe_data.DIRECTORY_ENTRY_IMPORT:
          for imp in entry.imports:
            if isinstance(imp.name, str):
              file.write(imp.name)
              file.write("\n")
    except Exception as e:
      print e

  def disassemble_exported_symbols(self, pe_data, file):
    try:
      if pe_data.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']].VirtualAddress != 0:
        pe_data.parse_data_directories(directories=[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']])
        for exp in pe_data.DIRECTORY_ENTRY_EXPORT.symbols:
          if isinstance(exp.name, str):
            file.write(exp.name)
            file.write("\n")
    except Exception as e:
      print e

  def extract_features(self, input_directory, output_filename, global_cluster_settings):
    cluster = self.cluster_settings(global_cluster_settings)
    data_list = self.get_dlls_from_data(input_directory)
    self.get_top_features(cluster, data_list, output_filename)

  def cluster_settings(self, global_cluster_settings):
    cluster_classifier = k_means.Kmeans()
    cluster_classifier.set_cluster_range(global_cluster_settings["lower_limit"], global_cluster_settings["upper_limit"])
    cluster_classifier.set_number_top_words(global_cluster_settings["number_top_words"])
    cluster_classifier.set_vectorizer(self.vectorizer)
    return cluster_classifier

  def get_top_features(self, cluster, data_list, output_filename):
    cluster.set_data(data_list)
    cluster.extract_top_features(output_filename)

  def get_dlls_from_data(self, input_directory):
    files = os.listdir(input_directory)
    dll_lists = []
    for file in files:
      file_name = input_directory + "/" + file
      file_dlls = self.list_string(self.read_file(file_name))
      dll_lists.append(file_dlls)
    return dll_lists

  def read_file(self, file_name):
    lines = [line.rstrip('\n') for line in open(file_name)]
    lines = np.unique(lines)
    return lines

  def list_string(self, data_list):
    document = ','.join(data_list)
    return document


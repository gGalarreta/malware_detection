from sklearn.feature_extraction.text import TfidfVectorizer
from raw_analysis import raw_analysis
from k_means import k_means
import sys
import pefile
import pydasm
import os
import numpy as np

class Opcode():

  def __init__(self):
    self.vectorizer = TfidfVectorizer(max_df = 0.75, max_features = 400000, min_df = 0.05, ngram_range=(5,5), use_idf=True, decode_error='ignore')
    self.n_grams = 5

  def disassemble(self, pe_data, file_name):
    file = open(file_name, "w")
    try:
      ep = pe_data.OPTIONAL_HEADER.AddressOfEntryPoint
      ep_ava = ep+pe_data.OPTIONAL_HEADER.ImageBase
      data = pe_data.get_memory_mapped_image()[ep:ep + self.size_of_raw_data(pe_data)]
      offset = 0
      while offset < len(data):
        i = pydasm.get_instruction(data[offset:], pydasm.MODE_32)
        instruction = pydasm.get_instruction_string(i, pydasm.FORMAT_INTEL, ep_ava+offset)
        if instruction == None :
          break
        offset += i.length
        file.write(instruction.split(' ', 1)[0])
        file.write('\n')
    except Exception as e:
      print e

  def size_of_raw_data(self, pe_data):
    raw_analyzer = raw_analysis.Raw()
    return raw_analyzer.size_of_raw_data(pe_data)


  def extract_features(self, input_directory, output_directory, global_cluster_settings):
    cluster = self.cluster_settings(global_cluster_settings)
    data_list = self.get_opcodes_from_data(input_directory)
    self.get_top_features(cluster, data_list, output_directory)

  def cluster_settings(self, global_cluster_settings):
    cluster_classifier = k_means.Kmeans()
    cluster_classifier.set_cluster_range(global_cluster_settings["lower_limit"], global_cluster_settings["upper_limit"])
    cluster_classifier.set_number_top_words(global_cluster_settings["number_top_words"])
    cluster_classifier.set_vectorizer(self.vectorizer)
    return cluster_classifier


  def get_opcodes_from_data(self, input_directory):
    files = os.listdir(input_directory)
    opcodes_lists = []
    for file in files:
      file_name = input_directory + "/" + file
      file_opcodes = self.list_string(self.read_file(file_name))
      opcodes_lists.append(file_opcodes)
    return opcodes_lists

  def read_file(self,file_name):
    lines = [line.rstrip('\n') for line in open(file_name)]
    return lines

  def list_string(self, data_list):
    document = ','.join(data_list)
    return document

  def get_top_features(self, cluster, data_list, output_directory):
    cluster.set_data(data_list)
    cluster.extract_top_features(output_directory)

  def ngrams(self, data_list):
    n_gram_vector = self.ngrams_structure(data_list, self.n_grams)
    return self.unique_list_of_lists(n_gram_vector)

  def ngrams_structure(self, data_list, size = 2, i = 0):
    while len(data_list[i:i+size]) == size:
      yield data_list[i:i+size]
      i +=1

  def unique_list_of_lists(self, data_list):
    unique_data = []
    for ngram_tuple in set(tuple(ngram) for ngram in data_list):
      unique_data = unique_data + [' '.join(list(ngram_tuple))]
    return unique_data
